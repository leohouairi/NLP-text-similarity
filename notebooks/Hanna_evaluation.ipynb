{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04b6b34-c474-4394-9585-85efe1f0e3fb",
   "metadata": {},
   "source": [
    "# Hanna evaluation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54395297-837a-4975-bc7a-fc9a80e04fb7",
   "metadata": {},
   "source": [
    "## 1 - Installation and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf3d35-58ca-4114-9c92-ee15b6dcad27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011988fe-c45c-460b-87c1-c8a3d69704e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sklearn\n",
    "import torch \n",
    "import transformers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from nlg_eval_via_simi_measures.bary_score import BaryScoreMetric\n",
    "from nlg_eval_via_simi_measures.depth_score import DepthScoreMetric\n",
    "from nlg_eval_via_simi_measures.infolm import InfoLM\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate import meteor\n",
    "from nltk import word_tokenize\n",
    "from nltk import download\n",
    "from bert_score import score\n",
    "from rouge import Rouge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4f83c-10dd-4d64-8b3b-f149e085cf52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download('punkt')\n",
    "download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf107e20-21b6-49b4-8d71-94469baea0d3",
   "metadata": {},
   "source": [
    "## 2 - score and corr computation functions def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd3020-a719-4e91-a430-e7ad068786d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bary(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    metric_call = BaryScoreMetric()\n",
    "    metric_call.prepare_idfs(ref, hypothesis)\n",
    "    return metric_call.evaluate_batch(ref, hypothesis)[\"baryscore_W\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7134384-f210-4758-838e-572ec2270017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_depthscore(ref:str,hypothesis:str):\n",
    "    metric_call = DepthScoreMetric()\n",
    "    metric_call.prepare_idfs(ref, hypothesis)\n",
    "    return metric_call.evaluate_batch(hypothesis,ref)[\"depth_score\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0a529-ddc9-48c7-bf7c-916ba44fb4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_infolmscore(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    metric = InfoLM()\n",
    "    #metric.device=\"cpu\"\n",
    "    #metric.model.to(\"cpu\")\n",
    "    metric.prepare_idfs(ref, hypothesis)\n",
    "    return metric.evaluate_batch(hypothesis, ref)[\"fisher_rao\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfee8f5-7836-4d4c-82d2-2c5a0ce35c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bleuscore(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[word_tokenize(ref)],word_tokenize(hypothesis)\n",
    "    return sentence_bleu(ref,hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6249e29-45c8-415b-ac9f-f05efa7e5956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bertscore(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    P, R, F1=score(hypothesis, ref, lang=\"en\", verbose=True)\n",
    "    return P.item(),R.item(),F1.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da6bbc-683d-4c09-ae87-c74c797c5cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import traceback\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BARTScorer:\n",
    "    def __init__(self, device='cuda:0', max_length=1024, checkpoint='facebook/bart-large-cnn'):\n",
    "        # Set up model\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = BartTokenizer.from_pretrained(checkpoint)\n",
    "        self.model = BartForConditionalGeneration.from_pretrained(checkpoint)\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "\n",
    "        # Set up loss\n",
    "        self.loss_fct = nn.NLLLoss(reduction='none', ignore_index=self.model.config.pad_token_id)\n",
    "        self.lsm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def load(self, path=None):\n",
    "        \"\"\" Load model from paraphrase finetuning \"\"\"\n",
    "        if path is None:\n",
    "            path = 'models/bart.pth'\n",
    "        self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
    "\n",
    "    def score(self, srcs, tgts, batch_size=4):\n",
    "        \"\"\" Score a batch of examples \"\"\"\n",
    "        score_list = []\n",
    "        for i in range(0, len(srcs), batch_size):\n",
    "            src_list = srcs[i: i + batch_size]\n",
    "            tgt_list = tgts[i: i + batch_size]\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    encoded_src = self.tokenizer(\n",
    "                        src_list,\n",
    "                        max_length=self.max_length,\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        return_tensors='pt'\n",
    "                    )\n",
    "                    encoded_tgt = self.tokenizer(\n",
    "                        tgt_list,\n",
    "                        max_length=self.max_length,\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        return_tensors='pt'\n",
    "                    )\n",
    "                    src_tokens = encoded_src['input_ids'].to(self.device)\n",
    "                    src_mask = encoded_src['attention_mask'].to(self.device)\n",
    "\n",
    "                    tgt_tokens = encoded_tgt['input_ids'].to(self.device)\n",
    "                    tgt_mask = encoded_tgt['attention_mask']\n",
    "                    tgt_len = tgt_mask.sum(dim=1).to(self.device)\n",
    "\n",
    "                    output = self.model(\n",
    "                        input_ids=src_tokens,\n",
    "                        attention_mask=src_mask,\n",
    "                        labels=tgt_tokens\n",
    "                    )\n",
    "                    logits = output.logits.view(-1, self.model.config.vocab_size)\n",
    "                    loss = self.loss_fct(self.lsm(logits), tgt_tokens.view(-1))\n",
    "                    loss = loss.view(tgt_tokens.shape[0], -1)\n",
    "                    loss = loss.sum(dim=1) / tgt_len\n",
    "                    curr_score_list = [-x.item() for x in loss]\n",
    "                    score_list += curr_score_list\n",
    "\n",
    "            except RuntimeError:\n",
    "                traceback.print_exc()\n",
    "                print(f'source: {src_list}')\n",
    "                print(f'target: {tgt_list}')\n",
    "                exit(0)\n",
    "        return score_list\n",
    "\n",
    "    def multi_ref_score(self, srcs, tgts: List[List[str]], agg=\"mean\", batch_size=4):\n",
    "        # Assert we have the same number of references\n",
    "        ref_nums = [len(x) for x in tgts]\n",
    "        if len(set(ref_nums)) > 1:\n",
    "            raise Exception(\"You have different number of references per test sample.\")\n",
    "\n",
    "        ref_num = len(tgts[0])\n",
    "        score_matrix = []\n",
    "        for i in range(ref_num):\n",
    "            curr_tgts = [x[i] for x in tgts]\n",
    "            scores = self.score(srcs, curr_tgts, batch_size)\n",
    "            score_matrix.append(scores)\n",
    "        if agg == \"mean\":\n",
    "            score_list = np.mean(score_matrix, axis=0)\n",
    "        elif agg == \"max\":\n",
    "            score_list = np.max(score_matrix, axis=0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return list(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd317f5-12dd-4fdf-bd45-279b9b9b21d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bartscore(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    bart_scorer = BARTScorer(device='cuda:0', checkpoint='facebook/bart-large-cnn')\n",
    "    return bart_scorer.multi_ref_score(hypothesis, ref, agg=\"max\", batch_size=4)[0] # agg means aggregation, can be mean or max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57a54d-a283-4058-b974-2c9144fa6e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_meteorscore(ref:str,hypothesis:str):\n",
    "    return round(meteor([word_tokenize(ref)],word_tokenize(hypothesis)),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053de45-af4f-4f3d-ad6f-c14d2768daf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def id(r,p,f):\n",
    "    return r,p,f\n",
    "\n",
    "def compute_rougescore(ref:str,hypothesis:str):\n",
    "    rouge = Rouge() \n",
    "    return id(**rouge.get_scores([hypothesis], [ref])[0]['rouge-1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52c036-a904-487d-929c-6345c5a7f4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_two_corr(dataframe:pd.DataFrame,column_name_1:str, column_name_2:str,correlation_type:str,system:str):\n",
    "    return dataframe[dataframe.Model==system][[column_name_1,column_name_2]].corr(method=correlation_type,numeric_only=True)\n",
    "\n",
    "def compute_list_corr(dataframe:pd.DataFrame,list_column_name:list[str],correlation_type:str,system:str=None):\n",
    "    if system:\n",
    "        return dataframe[dataframe.Model==system][list_column_name].corr(method=correlation_type)\n",
    "    else:\n",
    "        return dataframe[list_column_name].corr(method=correlation_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08189d72-22a2-492b-b3da-2a45808fcdc0",
   "metadata": {},
   "source": [
    "## 3 - DL and datawrangling of Hanna dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d20bc-679e-4645-9703-754be60dc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/dig-team/hanna-benchmark-asg/raw/main/hanna_stories_annotations.csv\")\n",
    "df_unique_human_story=df[df.Model!=\"Human\"][[\"Story ID\",\"Human\",\"Story\",\"Model\"]].drop_duplicates(keep=\"first\")\n",
    "df_human_index=df.Human.drop_duplicates(keep=\"first\").reset_index(drop=True).reset_index().rename(columns={\"index\":\"human_story_index\"})\n",
    "df_mean_human_metrics=df.groupby(\"Story ID\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ee63d-a49d-42f0-acf9-7d8afc895fb2",
   "metadata": {},
   "source": [
    "## 4 - Compute scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9821d1-3d72-40e7-a1a5-822b0796d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavy computation\n",
    "df_unique_human_story['baryscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_bary(*x), axis =1)\n",
    "df_unique_human_story['depthscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_depthscore(*x), axis =1)\n",
    "df_unique_human_story['infolmscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_infolmscore(*x), axis =1)\n",
    "df_unique_human_story['BLEU']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_bleuscore(*x), axis =1)\n",
    "df_unique_human_story[['ROUGE_r','ROUGE_p','ROUGE_f']]= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_rougescore(*x), axis =1, result_type=\"expand\")\n",
    "df_unique_human_story['meteorscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_meteorscore(*x), axis =1)\n",
    "df_unique_human_story['bartscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_bartscore(*x), axis =1)\n",
    "df_unique_human_story[['bertscore_p','bertscore_r','bertscore_f1']]= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_bertscore(*x), axis =1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093ff61-3075-4ed6-b256-d67a0c356ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unique_human_story_all=df_mean_human_metrics.merge(df_unique_human_story,how=\"left\",on=\"Story ID\")\n",
    "df_unique_human_story_all=df_unique_human_story_all.merge(df_human_index,on=\"Human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59b285-1422-481b-9ec3-ec8c58b917f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unique_human_story_all.to_parquet(\"hanna_scores_computed.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ff404-05d8-45b0-94a1-12b820190bf3",
   "metadata": {},
   "source": [
    "## 5 - Compute correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f4a7f-c538-45d2-ad02-68e398f77a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIST_HUMAN_METRICS=['Relevance','Coherence','Empathy','Surprise','Engagement','Complexity']\n",
    "LIST_AEM=['baryscore','depthscore','infolmscore','BLEU','ROUGE_r','ROUGE_p','ROUGE_f','meteorscore','bartscore','bertscore_p','bertscore_r','bertscore_f1']\n",
    "LIST_ALL_METRICS=LIST_HUMAN_METRICS+LIST_AEM\n",
    "CORR_METHODS=[\"pearson\", \"kendall\", \"spearman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5bec13-e67f-4ff2-8269-9d04ba580c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute text-level correlation\n",
    "\n",
    "\n",
    "for corr_method in CORR_METHODS:\n",
    "    print(corr_method)\n",
    "    # For each gold, compute AEM + HM (provided)\n",
    "\n",
    "    # >>> Done in  df_unique_human_story_all\n",
    "    df_work=df_unique_human_story_all.copy()\n",
    "    df_work=df_work.drop(columns=[\"Human\",\"Story\",\"Work time in seconds\",\"Story ID\"])\n",
    "    # For each gold (96), compute correlation 960 => 96 \n",
    "    list_of_dataframe=[]\n",
    "    for index in iter(df_work.human_story_index.unique()):\n",
    "        result=compute_list_corr(df_work[df_work[\"human_story_index\"]==index],LIST_ALL_METRICS,corr_method)\n",
    "        list_of_dataframe.append(result)\n",
    "\n",
    "    # Take the mean sample\n",
    "    #sns.heatmap(pd.DataFrame(np.mean(list(map(lambda x : x.to_numpy(),list_of_dataframe)),axis=0),columns=LIST_ALL_METRICS))\n",
    "    sns.heatmap(pd.concat(list_of_dataframe).groupby(level=0).mean().reindex(LIST_ALL_METRICS),annot=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89406b20-b241-4e9b-8466-b9c106483e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute system level correlation\n",
    "for corr_method in CORR_METHODS:\n",
    "    print(corr_method)\n",
    "    # For each gold, compute AEM + HM (provided)\n",
    "\n",
    "    # >>> Done in  df_unique_human_story_all\n",
    "    df_work=df_unique_human_story_all.copy()\n",
    "    df_work=df_work.drop(columns=[\"Human\",\"Story\",\"Work time in seconds\",\"Story ID\"])\n",
    "    # Take the mean sample for each system 960 => 10\n",
    "\n",
    "    df_work.groupby(\"Model\").mean()\n",
    "\n",
    "    # Compute correlation\n",
    "    sns.heatmap( compute_list_corr(df_work,LIST_ALL_METRICS,corr_method),annot=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2218fb3-1a6b-45fb-9d53-8b48cc8700a9",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbe88c-d460-47a9-ad9c-6298f9d8d70c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini=df_unique_human_story.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1091d33-591d-4f32-9aa1-9ba5242f52a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini['baryscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_bary(*x), axis =1)\n",
    "df_mini['depthscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_depthscore(*x), axis =1)\n",
    "df_mini['infolmscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_infolmscore(*x), axis =1)\n",
    "df_mini['BLEU']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_bleuscore(*x), axis =1)\n",
    "df_mini[['ROUGE_r','ROUGE_p','ROUGE_f']]= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_rougescore(*x), axis =1, result_type=\"expand\")\n",
    "df_mini['meteorscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_meteorscore(*x), axis =1)\n",
    "df_mini['bartscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_bartscore(*x), axis =1)\n",
    "df_mini[['bertscore_p','bertscore_r','bertscore_f1']]= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_bertscore(*x), axis =1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7611e8-2db3-487c-90ba-bd7408b132ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c5ae3b-f949-4e4e-96bf-c846209ed3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unique_human_only=df[df.Model==\"Human\"][[\"Human\",\"Story\"]].drop_duplicates(keep=\"first\")\n",
    "df_mini_human=df_unique_human_only.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c72ef2-10f9-4298-bafd-3ff66561207f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini_human['baryscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_bary(*x), axis =1)\n",
    "df_mini_human['depthscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_depthscore(*x), axis =1)\n",
    "df_mini_human['infolmscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_infolmscore(*x), axis =1)\n",
    "df_mini_human['BLEU']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_bleuscore(*x), axis =1)\n",
    "df_mini_human[['ROUGE_r','ROUGE_p','ROUGE_f']]= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_rougescore(*x), axis =1, result_type=\"expand\")\n",
    "df_mini_human['meteorscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_meteorscore(*x), axis =1)\n",
    "df_mini_human['bartscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_bartscore(*x), axis =1)\n",
    "df_mini_human[['bertscore_p','bertscore_r','bertscore_f1']]= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_bertscore(*x), axis =1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9bfaa-fb0d-4d06-8a30-1db8d6e98645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30423a0-643e-4551-a35b-8563d524c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{‘pearson’, ‘kendall’, ‘spearman’}\n",
    "sns.heatmap(compute_list_corr(df_unique_human_story_all,LIST_ALL_METRICS,'spearman','Human'),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1db41-7ea7-4f90-a0a7-9d679a54a2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_two_corr(df_unique_human_story_all,'baryscore','Relevance','spearman','Human')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
