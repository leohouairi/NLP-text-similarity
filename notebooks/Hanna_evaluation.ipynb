{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf3d35-58ca-4114-9c92-ee15b6dcad27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011988fe-c45c-460b-87c1-c8a3d69704e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sklearn\n",
    "import torch \n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from nlg_eval_via_simi_measures.bary_score import BaryScoreMetric\n",
    "from nlg_eval_via_simi_measures.depth_score import DepthScoreMetric\n",
    "from nlg_eval_via_simi_measures.infolm import InfoLM\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate import meteor\n",
    "from nltk import word_tokenize\n",
    "from nltk import download\n",
    "from bert_score import score\n",
    "from rouge import Rouge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4f83c-10dd-4d64-8b3b-f149e085cf52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download('punkt')\n",
    "download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb38c9-09ef-4aba-8070-3c41050a1130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/dig-team/hanna-benchmark-asg/raw/main/hanna_stories_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de18c41-cc02-4f19-83ed-d119efdf1b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unique_human_story=df[df.Model!=\"Human\"][[\"Human\",\"Story\"]].drop_duplicates(keep=\"first\")\n",
    "df_unique_human_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd3020-a719-4e91-a430-e7ad068786d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bary(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    metric_call = BaryScoreMetric()\n",
    "    metric_call.prepare_idfs(ref, hypothesis)\n",
    "    return metric_call.evaluate_batch(ref, hypothesis)[\"baryscore_W\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7134384-f210-4758-838e-572ec2270017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_depthscore(ref:str,hypothesis:str):\n",
    "    metric_call = DepthScoreMetric()\n",
    "    metric_call.prepare_idfs(ref, hypothesis)\n",
    "    return metric_call.evaluate_batch(hypothesis,ref)[\"depth_score\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0a529-ddc9-48c7-bf7c-916ba44fb4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_infolmscore(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    metric = InfoLM()\n",
    "    #metric.device=\"cpu\"\n",
    "    #metric.model.to(\"cpu\")\n",
    "    metric.prepare_idfs(ref, hypothesis)\n",
    "    return metric.evaluate_batch(hypothesis, ref)[\"fisher_rao\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfee8f5-7836-4d4c-82d2-2c5a0ce35c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bleuscore(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    return corpus_bleu(ref,hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6249e29-45c8-415b-ac9f-f05efa7e5956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bertscore(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    P, R, F1=score(hypothesis, ref, lang=\"en\", verbose=True)\n",
    "    return P.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da6bbc-683d-4c09-ae87-c74c797c5cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import traceback\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BARTScorer:\n",
    "    def __init__(self, device='cuda:0', max_length=1024, checkpoint='facebook/bart-large-cnn'):\n",
    "        # Set up model\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = BartTokenizer.from_pretrained(checkpoint)\n",
    "        self.model = BartForConditionalGeneration.from_pretrained(checkpoint)\n",
    "        self.model.eval()\n",
    "        self.model.to(device)\n",
    "\n",
    "        # Set up loss\n",
    "        self.loss_fct = nn.NLLLoss(reduction='none', ignore_index=self.model.config.pad_token_id)\n",
    "        self.lsm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def load(self, path=None):\n",
    "        \"\"\" Load model from paraphrase finetuning \"\"\"\n",
    "        if path is None:\n",
    "            path = 'models/bart.pth'\n",
    "        self.model.load_state_dict(torch.load(path, map_location=self.device))\n",
    "\n",
    "    def score(self, srcs, tgts, batch_size=4):\n",
    "        \"\"\" Score a batch of examples \"\"\"\n",
    "        score_list = []\n",
    "        for i in range(0, len(srcs), batch_size):\n",
    "            src_list = srcs[i: i + batch_size]\n",
    "            tgt_list = tgts[i: i + batch_size]\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    encoded_src = self.tokenizer(\n",
    "                        src_list,\n",
    "                        max_length=self.max_length,\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        return_tensors='pt'\n",
    "                    )\n",
    "                    encoded_tgt = self.tokenizer(\n",
    "                        tgt_list,\n",
    "                        max_length=self.max_length,\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        return_tensors='pt'\n",
    "                    )\n",
    "                    src_tokens = encoded_src['input_ids'].to(self.device)\n",
    "                    src_mask = encoded_src['attention_mask'].to(self.device)\n",
    "\n",
    "                    tgt_tokens = encoded_tgt['input_ids'].to(self.device)\n",
    "                    tgt_mask = encoded_tgt['attention_mask']\n",
    "                    tgt_len = tgt_mask.sum(dim=1).to(self.device)\n",
    "\n",
    "                    output = self.model(\n",
    "                        input_ids=src_tokens,\n",
    "                        attention_mask=src_mask,\n",
    "                        labels=tgt_tokens\n",
    "                    )\n",
    "                    logits = output.logits.view(-1, self.model.config.vocab_size)\n",
    "                    loss = self.loss_fct(self.lsm(logits), tgt_tokens.view(-1))\n",
    "                    loss = loss.view(tgt_tokens.shape[0], -1)\n",
    "                    loss = loss.sum(dim=1) / tgt_len\n",
    "                    curr_score_list = [-x.item() for x in loss]\n",
    "                    score_list += curr_score_list\n",
    "\n",
    "            except RuntimeError:\n",
    "                traceback.print_exc()\n",
    "                print(f'source: {src_list}')\n",
    "                print(f'target: {tgt_list}')\n",
    "                exit(0)\n",
    "        return score_list\n",
    "\n",
    "    def multi_ref_score(self, srcs, tgts: List[List[str]], agg=\"mean\", batch_size=4):\n",
    "        # Assert we have the same number of references\n",
    "        ref_nums = [len(x) for x in tgts]\n",
    "        if len(set(ref_nums)) > 1:\n",
    "            raise Exception(\"You have different number of references per test sample.\")\n",
    "\n",
    "        ref_num = len(tgts[0])\n",
    "        score_matrix = []\n",
    "        for i in range(ref_num):\n",
    "            curr_tgts = [x[i] for x in tgts]\n",
    "            scores = self.score(srcs, curr_tgts, batch_size)\n",
    "            score_matrix.append(scores)\n",
    "        if agg == \"mean\":\n",
    "            score_list = np.mean(score_matrix, axis=0)\n",
    "        elif agg == \"max\":\n",
    "            score_list = np.max(score_matrix, axis=0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return list(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd317f5-12dd-4fdf-bd45-279b9b9b21d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bartscore(ref:str,hypothesis:str):\n",
    "    ref,hypothesis=[ref],[hypothesis]\n",
    "    bart_scorer = BARTScorer(device='cuda:0', checkpoint='facebook/bart-large-cnn')\n",
    "    return bart_scorer.multi_ref_score(hypothesis, ref, agg=\"max\", batch_size=4)[0] # agg means aggregation, can be mean or max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57a54d-a283-4058-b974-2c9144fa6e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_meteorscore(ref:str,hypothesis:str):\n",
    "    return round(meteor([word_tokenize(ref)],word_tokenize(hypothesis)),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053de45-af4f-4f3d-ad6f-c14d2768daf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_rougescore(ref:str,hypothesis:str):\n",
    "    rouge = Rouge()\n",
    "    return rouge.get_scores([hypothesis], [ref])[0]['rouge-1']['p']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbe88c-d460-47a9-ad9c-6298f9d8d70c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini=df_unique_human_story.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1091d33-591d-4f32-9aa1-9ba5242f52a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini['baryscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_bary(*x), axis =1)\n",
    "df_mini['depthscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_depthscore(*x), axis =1)\n",
    "df_mini['infolmscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_infolmscore(*x), axis =1)\n",
    "df_mini['BLEU']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_bleuscore(*x), axis =1)\n",
    "df_mini['ROUGE']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_rougescore(*x), axis =1)\n",
    "df_mini['meteorscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_meteorscore(*x), axis =1)\n",
    "df_mini['bartscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_bartscore(*x), axis =1)\n",
    "df_mini['bertscore']= df_mini[[\"Human\", \"Story\"]].apply(lambda x : compute_bertscore(*x), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7611e8-2db3-487c-90ba-bd7408b132ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9821d1-3d72-40e7-a1a5-822b0796d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavy computation\n",
    "df_unique_human_story['baryscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_bary(*x), axis =1)\n",
    "df_unique_human_story['depthscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_depthscore(*x), axis =1)\n",
    "df_unique_human_story['infolmscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_infolmscore(*x), axis =1)\n",
    "df_unique_human_story['BLEU']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_bleuscore(*x), axis =1)\n",
    "df_unique_human_story['ROUGE']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_rougescore(*x), axis =1)\n",
    "df_unique_human_story['meteorscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_meteorscore(*x), axis =1)\n",
    "df_unique_human_story['bartscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_bartscore(*x), axis =1)\n",
    "df_unique_human_story['bertscore']= df_unique_human_story[[\"Human\", \"Story\"]].apply(lambda x : compute_bertscore(*x), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179a8df-ba36-479b-bac6-bd75553186be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unique_human_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c5ae3b-f949-4e4e-96bf-c846209ed3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unique_human_only=df[df.Model==\"Human\"][[\"Human\",\"Story\"]].drop_duplicates(keep=\"first\")\n",
    "df_mini_human=df_unique_human_only.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c72ef2-10f9-4298-bafd-3ff66561207f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini_human['baryscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_bary(*x), axis =1)\n",
    "df_mini_human['depthscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_depthscore(*x), axis =1)\n",
    "df_mini_human['infolmscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_infolmscore(*x), axis =1)\n",
    "df_mini_human['BLEU']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_bleuscore(*x), axis =1)\n",
    "df_mini_human['ROUGE']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_rougescore(*x), axis =1)\n",
    "df_mini_human['meteorscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_meteorscore(*x), axis =1)\n",
    "df_mini_human['bartscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_bartscore(*x), axis =1)\n",
    "df_mini_human['bertscore']= df_mini_human[[\"Human\", \"Story\"]].apply(lambda x : compute_bertscore(*x), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9bfaa-fb0d-4d06-8a30-1db8d6e98645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mini_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093ff61-3075-4ed6-b256-d67a0c356ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unique_human_story_all=df.merge(df_unique_human_story,how=\"left\",on=[\"Human\",\"Story\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
